{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16755, 19)\n",
      "(7247, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from SupervisedLearningUtils import *\n",
    "\n",
    "version=\"2.0\"\n",
    "dataset_folder = \"output-datasets\"\n",
    "results_path = f\"output-models/results_{version}.csv\"\n",
    "dataset_name = \"all_seasons_merged_mult_feature-selected\"\n",
    "dataset_path = f\"{dataset_folder}/{dataset_name}\"\n",
    "model_results = {}\n",
    "\n",
    "train = read_csv_and_get_inputs_and_labels(f\"{dataset_path}-train.csv\")\n",
    "test = read_csv_and_get_inputs_and_labels(f\"{dataset_path}-test.csv\")\n",
    "print(train[0].shape)\n",
    "print(test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def search_params(model_class, train, test, grid, n_iter=None):\n",
    "    CV_class = GridSearchCV if n_iter is None else RandomizedSearchCV\n",
    "    extra_params = {'n_iter': n_iter, 'param_distributions': grid} if n_iter is not None else {'param_grid': grid}\n",
    "    cross_validation = CV_class(estimator=model_class(), scoring=\"r2\", refit=False, **extra_params)\n",
    "    cross_validation.fit(train[0], train[1])\n",
    "    ideal_params = cross_validation.best_params_\n",
    "    print(f'Ideal parameters: {ideal_params}')\n",
    "    model_with_params = model_class(**ideal_params)\n",
    "    return test_model(model_with_params, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Results: ((0.9986247969099775, 0.7543883591408245), (-0.25616138593520543, 23.485300849633347))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree_results = test_model(decision_tree, train, test)\n",
    "print(f\"Decision Tree Regression Results: {decision_tree_results}\")\n",
    "model_results['decision_tree'] = decision_tree_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression\n",
    "1.0 is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression: ((0.7324492411797208, 10.522396242141225), (0.3447216052661092, 16.962362212075067))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# forest_param_search_grid = {'n_estimators':range(180, 261, 20),\n",
    "#                            'max_depth': [None, 80, 100, 120, 140],\n",
    "#                             'min_samples_leaf': [1, 2, 3, 5],\n",
    "#                             'min_samples_split': [2, 5, 10],\n",
    "#                            'max_features': ['auto', 'sqrt', 'log2']}\n",
    "# random_forest_results = search_params(model_class=RandomForestRegressor, train=train, test=test, grid=forest_param_search_grid, n_iter=10)\n",
    "ideal_params = {'n_estimators': 1000, 'min_samples_split': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'max_depth': None}\n",
    "ideal_model = RandomForestRegressor(**ideal_params)\n",
    "random_forest_results = test_model(ideal_model, train, test)\n",
    "print(f\"Random Forest Regression: {random_forest_results}\")\n",
    "model_results['random_forest'] = random_forest_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Regressor: ((0.41457009265948463, 15.789280096146841), (0.38556066926271126, 16.980486111278786))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gardient_boost_regressor = GradientBoostingRegressor()\n",
    "gradient_boost_regressor_results = test_model(gardient_boost_regressor, train, test)\n",
    "print(f\"Gradient Boost Regressor: {gradient_boost_regressor_results}\")\n",
    "model_results['gradient_boost_regressor'] = gradient_boost_regressor_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "Different alpha values attempted for all_seasons_merged_mult, Yields same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge: ((0.3806240534812315, 16.240599038021973), (0.3897327310573063, 16.922738908715058))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_results = test_model(ridge_model, train, test)\n",
    "print(f\"Ridge: {ridge_results}\")\n",
    "model_results['ridge'] = ridge_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Regression: ((0.38468792256103335, 15.957295162437317), (0.32682172669428267, 17.192477067151437))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "neural_model = MLPRegressor(max_iter=2500, hidden_layer_sizes=(50, 50, 50, 50, 10))\n",
    "neural_results = test_model(neural_model, train, test)\n",
    "print(f\"Neural Network Regression: {neural_results}\")\n",
    "model_results['neural_network'] = neural_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_formatted_results = {}\n",
    "## Format new results\n",
    "for model_name, result in model_results.items():\n",
    "    new_formatted_results[model_name] = [*result[0], *result[1]]\n",
    "## Read in existing results\n",
    "existing_results = {}\n",
    "try:\n",
    "    with open(results_path, 'r', newline='') as file:\n",
    "        headers = None\n",
    "        for row in csv.reader(file, delimiter=','):\n",
    "            if headers is None:\n",
    "                headers = row\n",
    "                continue\n",
    "            prev_dataset_name = row[0]\n",
    "            model_name = row[1]\n",
    "\n",
    "            if prev_dataset_name not in existing_results:\n",
    "                existing_results[prev_dataset_name] = {}\n",
    "            existing_results[prev_dataset_name][model_name] = row[2:]\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "formatted_results = dict(existing_results, **{dataset_name: new_formatted_results})\n",
    "with open(results_path, 'w+', newline='') as file: \n",
    "    if headers is None:\n",
    "        headers = ['dataset', 'model', 'train_r_2', 'train_rmse', 'test_r_2', 'test_rmse']\n",
    "    \n",
    "    output = [headers]\n",
    "    # write results\n",
    "    for dataset_name, formatted_model_results in formatted_results.items():\n",
    "        for model_name, model_result in formatted_model_results.items():\n",
    "            if len(headers) - 2 != len(model_result):\n",
    "                raise ValueError(f'Length of headers does not match: {model_result}')\n",
    "            output.append([dataset_name, model_name, *model_result])\n",
    "    file.truncate(0)\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerows(output)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
